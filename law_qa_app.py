#!/usr/bin/env python3
"""
ğŸ“œ Streamlit â€“ ë²•ë ¹Â·íŒë¡€ Q&A (ê°œì„ ëœ ë²„ì „)
- Think/Non-think ëª¨ë“œ (Gemini 2.5 Pro thinking API í™œìš©)
- ê°„ë‹¨/ìƒì„¸ ì…ë ¥ ëª¨ë“œ  
- ê°œì„ ëœ ê°ì£¼ ë Œë”ë§
- ë™ì  ë²•ë ¹/íŒë¡€ ìš”ì²­ ê¸°ëŠ¥
- íŒë¡€ ë°ì´í„° ì „ë‹¬ ê°œì„ 

ì„¤ì¹˜:  pip install -U streamlit chromadb google-genai python-dotenv
ì‹¤í–‰:  streamlit run law_qa_app.py
"""
from __future__ import annotations
import os, re, html, json, sqlite3, textwrap, time, asyncio
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional

import streamlit as st
from streamlit.runtime.scriptrunner import add_script_run_ctx
from dotenv import load_dotenv
from google import genai          # type: ignore
import chromadb                   # type: ignore
from chromadb.config import Settings
from google.genai import types
from google.genai.types import EmbedContentConfig

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ê°’ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    raise RuntimeError("âš ï¸  .env íŒŒì¼ì— GEMINI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")

CHROMA_DIR   = "./data/ChromaLegal"
COL_LAW      = "laws"
COL_PREC     = "precs"
EMBED_MODEL  = "gemini-embedding-exp-03-07"
GEN_MODEL_THINK = "gemini-2.5-flash"  # thinking API ì§€ì›
GEN_MODEL_NORMAL = "gemini-2.5-flash"
TOP_K        = 8
TEMP         = 0.2
MAX_TOK      = 65536
DB_PATH      = "./data/laws/laws.db"
PRE_LAW_DIR  = Path("./data/laws/preprocess")
PRE_PREC_DIR = Path("./data/precs/preprocess")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í´ë¼ì´ì–¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
g_client = genai.Client(api_key=API_KEY)

ch_set  = Settings(is_persistent=True,
                   persist_directory=CHROMA_DIR,
                   anonymized_telemetry=False)
ch_cli  = chromadb.PersistentClient(settings=ch_set)
col_law = ch_cli.get_or_create_collection(COL_LAW)
col_prec= ch_cli.get_or_create_collection(COL_PREC)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Streamlit ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config("ğŸ“œ ë²•ë ¹Â·íŒë¡€ Q&A", "ğŸ“œ", layout="wide")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.markdown("## âš™ï¸ ì„¤ì •")
    
    # Think ëª¨ë“œ ì„¤ì •
    think_mode = st.selectbox(
        "ğŸ§  ì¶”ë¡  ëª¨ë“œ",
        options=["Think ëª¨ë“œ", "Non-Think ëª¨ë“œ"],
        help="Think ëª¨ë“œ: Gemini 2.5 Flash + ìƒì„¸ ì¶”ë¡  ê³¼ì •\nNon-Think ëª¨ë“œ: Gemini 2.5 Flash + ë¹ ë¥¸ ë‹µë³€"
    )
    
    # ì…ë ¥ ëª¨ë“œ ì„¤ì •
    input_mode = st.selectbox(
        "ğŸ“ ì…ë ¥ ëª¨ë“œ", 
        options=["ê°„ë‹¨ ì…ë ¥", "ìƒì„¸ ì…ë ¥"],
        help="ê°„ë‹¨ ì…ë ¥: ììœ  í…ìŠ¤íŠ¸\nìƒì„¸ ì…ë ¥: êµ¬ì¡°í™”ëœ ì–‘ì‹"
    )
    
    # ë™ì  ê²€ìƒ‰ ì„¤ì •
    dynamic_search = st.checkbox(
        "ğŸ”„ ë™ì  ê²€ìƒ‰",
        value=True,
        help="AIê°€ ì¶”ë¡  ì¤‘ ì¶”ê°€ ë²•ë ¹/íŒë¡€ë¥¼ ìš”ì²­í•  ìˆ˜ ìˆë„ë¡ í—ˆìš©"
    )
    
    st.markdown("---")
    st.markdown("### ğŸ“Š í†µê³„")
    
    # DB í†µê³„ í‘œì‹œ
    try:
        with sqlite3.connect(DB_PATH) as conn:
            law_count = conn.execute("SELECT COUNT(*) FROM laws").fetchone()[0]
            prec_count = conn.execute("SELECT COUNT(*) FROM precedents").fetchone()[0]
            st.metric("ë²•ë ¹ ìˆ˜", f"{law_count:,}")
            st.metric("íŒë¡€ ìˆ˜", f"{prec_count:,}")
    except:
        st.error("DB ì—°ê²° ì‹¤íŒ¨")

# ë©”ì¸ íƒ€ì´í‹€
st.markdown("<h1 style='margin-top:0'>ğŸ“œ ë²•ë ¹Â·íŒë¡€ ê¸°ë°˜ Q&A</h1>", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'search_query' not in st.session_state:
    st.session_state.search_query = ""
if 'should_search' not in st.session_state:
    st.session_state.should_search = False
if 'thinking_requests' not in st.session_state:
    st.session_state.thinking_requests = []

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—¬í¼ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False, ttl="1d")
def embed_text(txt: str) -> List[float]:
    """Gemini ì„ë² ë”©"""
    try:
        res = g_client.models.embed_content(
            model=EMBED_MODEL,
            contents=txt,
            config=EmbedContentConfig(
                task_type="RETRIEVAL_DOCUMENT",
                output_dimensionality=3072,
            )
        )
        return res.embeddings[0].values  # type: ignore
    except Exception as e:
        st.error(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
        return []

def _query(col, v, n_results: int = TOP_K) -> List[Dict[str, Any]]:
    if not v:
        return []
    try:
        r = col.query(query_embeddings=[v],
                      n_results=n_results,
                      include=["documents", "metadatas", "distances"])
        out = []
        for i in range(len(r["ids"][0])):
            out.append({
                "id"   : r["ids"][0][i],
                "text" : r["documents"][0][i],
                "meta" : r["metadatas"][0][i],
                "score": r["distances"][0][i],
            })
        return out
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë°ì´í„° ë§¤í•‘ êµ¬ì¶• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False)
def build_name_map() -> Dict[str, str]:
    """ë²•ë ¹Â·íŒë¡€ 'ì œëª© â†’ parent_id' ë§¤í•‘"""
    mp: Dict[str, str] = {}
    for p in PRE_LAW_DIR.glob("*.json"):
        try:
            with p.open(encoding="utf-8") as f:
                data = json.load(f)
                title = data.get("title") or p.stem
                mp[title] = data.get("law_id", p.stem)
        except Exception:
            continue
    for p in PRE_PREC_DIR.glob("*.json"):
        try:
            with p.open(encoding="utf-8") as f:
                data = json.load(f)
                title = data.get("title") or p.stem
                mp[title] = data.get("prec_id", p.stem)
        except Exception:
            continue
    return mp

NAME2ID = build_name_map()

@st.cache_data(show_spinner=False)
def valid_ids_from_db() -> set[str]:
    """ì¡´ì¬í•˜ëŠ” parent_id ì§‘í•©"""
    ids: set[str] = set()
    try:
        with sqlite3.connect(DB_PATH) as conn:
            ids.update(r[0] for r in conn.execute("SELECT law_id FROM laws"))
            ids.update(r[0] for r in conn.execute("SELECT prec_id FROM precedents"))
    except Exception:
        pass
    return ids

VALID_IDS = valid_ids_from_db()

def load_json(parent_id: str) -> Dict[str, Any] | None:
    try:
        law_file = PRE_LAW_DIR / f"{parent_id}.json"
        if law_file.exists():
            return json.load(law_file.open("r", encoding="utf-8"))
        prec_file = PRE_PREC_DIR / f"{parent_id}.json"
        if prec_file.exists():
            return json.load(prec_file.open("r", encoding="utf-8"))
    except Exception:
        pass
    return None

def json_to_fulltext(data: Dict[str, Any]) -> str:
    """JSON â†’ ë³¸ë¬¸ ì „ì²´ ë¬¸ìì—´"""
    content = data.get("content", "")
    if content:
        return content
    # ë°±ì—…: ë‹¤ë¥¸ í•„ë“œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    if "articles" in data:
        return "\n".join(a.get("text", "") for a in data["articles"])
    if "judgement" in data:
        return data["judgement"]
    return ""

def is_law_document(doc_id: str, doc_meta: Dict[str, Any]) -> bool:
    """ë¬¸ì„œê°€ ë²•ë ¹ì¸ì§€ íŒë¡€ì¸ì§€ ì •í™•íˆ íŒë‹¨"""
    # 1. ID ê¸°ë°˜ íŒë‹¨ (ê°€ì¥ í™•ì‹¤)
    if doc_id.startswith("PREC_") or doc_id.startswith("prec_"):
        return False
    if doc_id.startswith("LAW_") or doc_id.startswith("law_"):
        return True
    
    # 2. ë©”íƒ€ë°ì´í„° ê¸°ë°˜ íŒë‹¨
    doc_type = doc_meta.get("type", "").lower()
    if doc_type in ["precedent", "íŒë¡€", "prec"]:
        return False
    if doc_type in ["law", "ë²•ë ¹", "ë²•ë¥ "]:
        return True
    
    # 3. parent_id ê¸°ë°˜ íŒë‹¨
    parent_id = doc_meta.get("parent_id", "")
    if parent_id.startswith("PREC_") or parent_id.startswith("prec_"):
        return False
    if parent_id.startswith("LAW_") or parent_id.startswith("law_"):
        return True
    
    # 4. ì œëª© ê¸°ë°˜ íŒë‹¨
    title = doc_meta.get("title", "")
    if "íŒë¡€" in title or "ëŒ€ë²•ì›" in title or "í—Œë²•ì¬íŒì†Œ" in title:
        return False
    if title.endswith("ë²•") or title.endswith("ë ¹") or title.endswith("ê·œì¹™"):
        return True
    
    # 5. ë‚´ìš© ê¸°ë°˜ íŒë‹¨ (JSON ë°ì´í„° í™•ì¸)
    data = load_json(parent_id or doc_id)
    if data:
        if "judgment" in data or "judgement" in data or "court" in data:
            return False
        if "articles" in data or "provisions" in data:
            return True
    
    # ê¸°ë³¸ê°’: ë²•ë ¹ìœ¼ë¡œ ê°„ì£¼
    return True

def fix_markdown_bold(text: str) -> str:
    """ë§ˆí¬ë‹¤ìš´ ë³¼ë“œì²´ ë¬¸ì œ í•´ê²° - ê°œì„ ëœ ë²„ì „"""
    def bold_replacer(match):
        content = match.group(1).strip()
        if content:
            return f'**{content}**'
        return match.group(0)
    
    # **ë‚´ìš©** íŒ¨í„´ ë§¤ì¹­ (íŠ¹ìˆ˜ë¬¸ì í¬í•¨)
    text = re.sub(r'\*\*([^*\n]+?)\*\*', bold_replacer, text)
    return text

def sanitize_html(raw: str) -> str:
    """ë¶ˆí•„ìš” HTML íƒœê·¸ ì°¨ë‹¨ ë° ë§ˆí¬ë‹¤ìš´ ë³¼ë“œì²´ ìˆ˜ì •"""
    allowed = {"sup", "sub", "span", "br", "b", "strong", "i", "em", "table", "tr", "td", "th", "thead", "tbody", "a"}
    sanitized = re.sub(
        r"</?([a-zA-Z0-9]+)[^>]*>",
        lambda m: m.group(0) if m.group(1).lower() in allowed
        else html.escape(m.group(0)),
        raw,
    )
    return fix_markdown_bold(sanitized)

def filter_hallucinated(txt: str) -> str:
    """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” parent_idë¥¼ [INVALID-â€¦]ë¡œ ì¹˜í™˜"""
    pat = r"(LAW|PREC)_([0-9]+)"
    def repl(m):
        pid = m.group(2)
        if pid in VALID_IDS:
            return m.group(0)
        return f"[INVALID-{pid}]"
    return re.sub(pat, repl, txt)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê°ì£¼ ì²˜ë¦¬ ê°œì„  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def convert_to_html_footnotes(text: str) -> str:
    """ê°ì£¼ë¥¼ Streamlit í˜¸í™˜ HTMLë¡œ ë³€í™˜"""
    def footnote_repl(match):
        num = match.group(1)
        return f'<sup><a href="#footnote-{num}" onclick="scrollToFootnote({num})" style="text-decoration:none; color:#1f77b4; font-weight:bold; cursor:pointer;">[{num}]</a></sup>'
    
    return re.sub(r'\[\^(\d+)\]', footnote_repl, text)

def extract_footnote_sources(text: str) -> List[Tuple[int, str]]:
    """ê°ì£¼ ì†ŒìŠ¤ ì¶”ì¶œ"""
    sources = []
    source_section_match = re.search(r'## ì¶œì²˜\s*\n(.*?)(?=\n##|\Z)', text, re.S)
    if not source_section_match:
        return sources
    
    source_content = source_section_match.group(1)
    lines = source_content.split('\n')
    
    for line in lines:
        line = line.strip()
        if line.startswith('[^') and ']' in line:
            match = re.match(r'\[\^(\d+)\]\s*(.*)', line)
            if match:
                num = int(match.group(1))
                content = match.group(2)
                sources.append((num, content))
    
    return sources

def render_footnotes_section(footnote_sources: List[Tuple[int, str]]) -> str:
    """ê°ì£¼ ì„¹ì…˜ì„ HTMLë¡œ ë Œë”ë§"""
    if not footnote_sources:
        return ""
    
    footnotes_html = []
    for num, content in footnote_sources:
        footnotes_html.append(
            f'<div id="footnote-{num}" style="margin-bottom: 15px; padding: 12px; background-color: #f8f9fa; border-left: 4px solid #1f77b4; border-radius: 6px; line-height: 1.6;">'
            f'<div style="margin-bottom: 8px;">'
            f'<sup><strong style="color: #1f77b4; font-size: 14px;">[{num}]</strong></sup> '
            f'<a href="#footnote-ref-{num}" onclick="scrollToFootnoteRef({num})" style="float: right; color: #666; text-decoration: none; font-size: 12px; cursor: pointer;">â†‘ ëŒì•„ê°€ê¸°</a>'
            f'</div>'
            f'<div style="margin-left: 8px; color: #333;">{content}</div>'
            f'</div>'
        )
    
    scroll_js = """
    <script>
    function scrollToFootnote(num) {
        const element = document.getElementById('footnote-' + num);
        if (element) {
            element.scrollIntoView({ behavior: 'smooth', block: 'center' });
            element.style.backgroundColor = '#e3f2fd';
            setTimeout(() => { element.style.backgroundColor = '#f8f9fa'; }, 2000);
        }
    }
    
    function scrollToFootnoteRef(num) {
        const refs = document.querySelectorAll('a[href="#footnote-' + num + '"]');
        if (refs.length > 0) {
            refs[0].scrollIntoView({ behavior: 'smooth', block: 'center' });
            refs[0].style.backgroundColor = '#fff3cd';
            setTimeout(() => { refs[0].style.backgroundColor = 'transparent'; }, 2000);
        }
    }
    </script>
    """
    
    return (
        '<div style="border-top: 2px solid #ddd; margin-top: 30px; padding-top: 25px;">'
        '<h3 style="color: #1f77b4; margin-bottom: 20px; font-size: 20px; border-bottom: 1px solid #ddd; padding-bottom: 10px;">ğŸ“š ì°¸ê³  ìë£Œ</h3>'
        + ''.join(footnotes_html) + 
        '</div>' + scroll_js
    )

def remove_source_section(text: str) -> str:
    """## ì¶œì²˜ ì„¹ì…˜ ì œê±°"""
    return re.sub(r'## ì¶œì²˜\s*\n.*?(?=\n##|\Z)', '', text, flags=re.S).strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë™ì  ê²€ìƒ‰ ê¸°ëŠ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def search_specific_law_or_precedent(query: str, doc_type: str = "both") -> List[Dict[str, Any]]:
    """íŠ¹ì • ë²•ë ¹ì´ë‚˜ íŒë¡€ ê²€ìƒ‰"""
    v = embed_text(query)
    results = []
    
    if doc_type in ["law", "both"]:
        law_results = _query(col_law, v, n_results=3)
        for doc in law_results:
            doc["meta"]["type"] = "law"
        results.extend(law_results)
    
    if doc_type in ["precedent", "both"]:
        prec_results = _query(col_prec, v, n_results=3)
        for doc in prec_results:
            doc["meta"]["type"] = "precedent"
        results.extend(prec_results)
    
    return sorted(results, key=lambda d: d["score"])[:5]

def process_thinking_requests(thinking_text: str) -> str:
    """ì¶”ë¡  ê³¼ì •ì—ì„œ ì¶”ê°€ ìë£Œ ìš”ì²­ ì²˜ë¦¬"""
    if not st.session_state.get('dynamic_search', True):
        return thinking_text
    
    # ìš”ì²­ íŒ¨í„´ ì°¾ê¸°
    request_patterns = [
        r"(?:ì¶”ê°€ë¡œ|ë”|ë˜í•œ)\s*(?:í•„ìš”í•œ|ê´€ë ¨ëœ|ì°¾ì•„ë³´ê³ \s*ì‹¶ì€)\s*(?:ë²•ë ¹|íŒë¡€|ìë£Œ):\s*(.+?)(?:\n|$)",
        r"(?:ê²€ìƒ‰|ì°¾ê¸°)\s*ìš”ì²­:\s*(.+?)(?:\n|$)",
        r"(?:ë”\s*ìì„¸í•œ|êµ¬ì²´ì ì¸)\s*(?:ë²•ë ¹|íŒë¡€)(?:ê°€|ì„)\s*(?:í•„ìš”ë¡œ|ì›í•¨):\s*(.+?)(?:\n|$)"
    ]
    
    enhanced_thinking = thinking_text
    
    for pattern in request_patterns:
        matches = re.findall(pattern, thinking_text, re.IGNORECASE)
        for match in matches:
            query = match.strip()
            if len(query) > 5:  # ì˜ë¯¸ìˆëŠ” ì¿¼ë¦¬ë§Œ ì²˜ë¦¬
                additional_docs = search_specific_law_or_precedent(query)
                if additional_docs:
                    doc_summary = "\n".join([
                        f"- {doc['meta'].get('title', doc['id'])[:100]}..."
                        for doc in additional_docs[:3]
                    ])
                    enhanced_thinking += f"\n\n[ì¶”ê°€ ê²€ìƒ‰ ê²°ê³¼: {query}]\n{doc_summary}"
    
    return enhanced_thinking

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²€ìƒ‰ & í”„ë¡¬í”„íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def retrieve(q: str) -> List[Dict[str, Any]]:
    """ê°œì„ ëœ ê²€ìƒ‰: ë²•ë ¹ê³¼ íŒë¡€ ê· í˜•ìˆê²Œ ê°€ì ¸ì˜¤ê¸°"""
    # 1. ëª…ì‹œì  ì´ë¦„ í˜¸ì¶œ
    explicit_docs: List[Dict[str, Any]] = []
    for name, pid in NAME2ID.items():
        if name in q:
            data = load_json(pid)
            if data:
                explicit_docs.append({
                    "id": pid,
                    "text": json_to_fulltext(data),
                    "meta": {"parent_id": pid, "title": name, "type": "explicit"},
                    "score": 0.0,
                })

    # 2. ì„ë² ë”© ê²€ìƒ‰ - ë²•ë ¹ê³¼ íŒë¡€ ë³„ë„ë¡œ
    v = embed_text(q)
    law_docs = _query(col_law, v, n_results=6)
    prec_docs = _query(col_prec, v, n_results=6)
    
    # íƒ€ì… ì •ë³´ ì¶”ê°€
    for doc in law_docs:
        doc["meta"]["type"] = "law"
    for doc in prec_docs:
        doc["meta"]["type"] = "precedent"
    
    # ê²°í•© ë° ì •ë ¬
    all_docs = explicit_docs + law_docs + prec_docs
    all_docs.sort(key=lambda d: d["score"])
    
    return all_docs[:TOP_K]

def build_prompt_improved(q: str, docs: List[Dict[str, Any]]) -> str:
    """ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì„± - ë²•ë ¹ê³¼ íŒë¡€ êµ¬ë¶„"""
    law_docs = [d for d in docs if is_law_document(d["id"], d["meta"])]
    prec_docs = [d for d in docs if not is_law_document(d["id"], d["meta"])]
    
    # ë²•ë ¹ ì„¹ì…˜
    law_ctx = []
    for i, d in enumerate(law_docs, 1):
        title = d["meta"].get("title", d["id"])
        law_ctx.append(f"[ë²•ë ¹{i}] {title}\n{d['text'][:2000]}")  # ê¸¸ì´ ì œí•œ
    
    # íŒë¡€ ì„¹ì…˜  
    prec_ctx = []
    for i, d in enumerate(prec_docs, 1):
        title = d["meta"].get("title", d["id"])
        prec_ctx.append(f"[íŒë¡€{i}] {title}\n{d['text'][:2000]}")  # ê¸¸ì´ ì œí•œ
    
    law_section = "\n\n".join(law_ctx) if law_ctx else "ê´€ë ¨ ë²•ë ¹ ì—†ìŒ"
    prec_section = "\n\n".join(prec_ctx) if prec_ctx else "ê´€ë ¨ íŒë¡€ ì—†ìŒ"
    
    dynamic_note = ""
    if st.session_state.get('dynamic_search', True):
        dynamic_note = "\n\n[ì°¸ê³ ] ì¶”ë¡  ì¤‘ ì¶”ê°€ ë²•ë ¹ì´ë‚˜ íŒë¡€ê°€ í•„ìš”í•˜ë©´ 'ì¶”ê°€ í•„ìš”í•œ ë²•ë ¹: [ë²•ë ¹ëª…]' ë˜ëŠ” 'ì¶”ê°€ í•„ìš”í•œ íŒë¡€: [í‚¤ì›Œë“œ]' í˜•íƒœë¡œ ìš”ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    
    return f"""[ì§ˆë¬¸]
{q}

[ê´€ë ¨ ë²•ë ¹]
{law_section}

[ê´€ë ¨ íŒë¡€]  
{prec_section}{dynamic_note}"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT_THINK = textwrap.dedent("""
    ë„ˆëŠ” í•œêµ­ì˜ **ë²•ë ¹ê³¼ íŒë¡€**ë¥¼ ë™ì‹œì— ì°¸ê³ í•˜ì—¬ ë²•ë¥  ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì „ë¬¸ AIì´ë‹¤.
    
    ## ìƒì„¸í•œ ì¶”ë¡  ê³¼ì • (ë‹¨ê³„ ì œí•œ ì—†ìŒ):
    ê° ë‹¨ê³„ë³„ë¡œ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ë©°, í•„ìš”í•œ ë§Œí¼ ë‹¨ê³„ë¥¼ ëŠ˜ë ¤ë„ ëœë‹¤:
    
    1) **ì§ˆë¬¸ ë¶„ì„**: ë²•ì  ìŸì , í•µì‹¬ í‚¤ì›Œë“œ, ê´€ë ¨ ë²• ì˜ì—­ íŒŒì•…
    2) **ë²•ë ¹ ê²€í† **: ì œê³µëœ ë²•ë ¹ì˜ ì¡°ë¬¸ë³„ ìƒì„¸ ë¶„ì„
    3) **íŒë¡€ ë¶„ì„**: íŒë¡€ì˜ ì‚¬ì‹¤ê´€ê³„, ë²•ë¦¬, íŒì‹œì‚¬í•­ ê²€í† 
    4) **ë²•ë¦¬ì  ì¢…í•©**: ë²•ë ¹ê³¼ íŒë¡€ ê°„ ê´€ê³„, í•´ì„ë¡ , ì ìš© ê¸°ì¤€
    5) **ì‚¬ì•ˆ ì ìš©**: êµ¬ì²´ì  ì‚¬ì‹¤ì— ë²•ë¦¬ ì ìš©
    6) **ê²°ë¡  ë„ì¶œ**: ìµœì¢… ë²•ì  íŒë‹¨ ë° ê·¼ê±°
    7) **ì¶”ê°€ ê³ ë ¤ì‚¬í•­**: ì˜ˆì™¸, ì£¼ì˜ì , ì‹¤ë¬´ìƒ ê³ ë ¤ì‚¬í•­
    
    ì¶”ë¡  ì¤‘ ë” êµ¬ì²´ì ì¸ ë²•ë ¹ì´ë‚˜ íŒë¡€ê°€ í•„ìš”í•˜ë©´ ìš”ì²­í•  ìˆ˜ ìˆë‹¤.

    ## ìµœì¢… ë‹µë³€ êµ¬ì¡°:
    **ã€í•µì‹¬ ê²°ë¡ ã€‘**
    - 3ì¤„ ìš”ì•½ìœ¼ë¡œ í•µì‹¬ ê²°ë¡  ì œì‹œ

    **I. ì‚¬ì•ˆì˜ ì •ë¦¬**
    **II. ê´€ë ¨ ë²•ë ¹ ë¶„ì„**
    **III. íŒë¡€ ê²€í† **  
    **IV. ë²•ë¦¬ì  ë¶„ì„**
    **V. ê²°ë¡  ë° ì‹¤ë¬´ ì¡°ì¹˜**
    
    ## ê·œì¹™:
    - ì œê³µëœ ìë£Œë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ë˜, ë¶€ì¡±í•˜ë©´ ì¶”ê°€ ìš”ì²­
    - ê·¼ê±°ê°€ ìˆëŠ” ë‚´ìš©ë§Œ ë‹¨ì •ì ìœ¼ë¡œ ê¸°ìˆ 
    - ê°ì£¼ [^n]ë¡œ ì¶œì²˜ ëª…ì‹œ
    - ì‹¤ë¬´ì  ì¡°ì¹˜ë°©ì•ˆê¹Œì§€ ì œì‹œ
""")

SYSTEM_PROMPT_NON_THINK = textwrap.dedent("""
    ë„ˆëŠ” í•œêµ­ì˜ **ë²•ë ¹ê³¼ íŒë¡€**ë¥¼ ë™ì‹œì— ì°¸ê³ í•˜ì—¬ ë²•ë¥  ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì „ë¬¸ AIì´ë‹¤.

    ## ë‹µë³€ êµ¬ì¡°:
    **ã€í•µì‹¬ ê²°ë¡ ã€‘**
    - 3ì¤„ ìš”ì•½ìœ¼ë¡œ í•µì‹¬ ê²°ë¡  ì œì‹œ

    **I. ì‚¬ì•ˆì˜ ì •ë¦¬**
    **II. ê´€ë ¨ ë²•ë ¹ ë¶„ì„**
    **III. íŒë¡€ ê²€í† **  
    **IV. ë²•ë¦¬ì  ë¶„ì„**
    **V. ê²°ë¡  ë° ì‹¤ë¬´ ì¡°ì¹˜**

    ## ê·œì¹™:
    - ì œê³µëœ [ê´€ë ¨ ë²•ë ¹]ê³¼ [ê´€ë ¨ íŒë¡€] ìë£Œë¥¼ **ë°˜ë“œì‹œ** í™œìš©
    - ê·¼ê±° ë¬¸ì¥ë§ˆë‹¤ ê°ì£¼ [^n] í‘œê¸° (1ë¶€í„° ìˆœì°¨)
    - í™•ì‹¤í•˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  í•œê³„ë¥¼ ëª…ì‹œ
    - ì‹¤ë¬´ì  ì¡°ì¹˜ë°©ì•ˆê¹Œì§€ ì œì‹œ
""")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Think ëª¨ë“œ ì²˜ë¦¬ (Gemini 2.5 Flash API) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_with_thinking(prompt: str, system_prompt: str) -> Tuple[str, str]:
    """Gemini 2.5 Flash thinking APIë¥¼ ì‚¬ìš©í•œ ìƒì„±"""
    try:
        thoughts = ""
        answer = ""
        
        # Thinking API ì‚¬ìš©
        for chunk in g_client.models.generate_content_stream(
            model=GEN_MODEL_THINK,
            contents=prompt,
            config=types.GenerateContentConfig(
                system_instruction=system_prompt,
                temperature=TEMP,
                top_p=0.8,
                top_k=20,
                max_output_tokens=MAX_TOK,
                thinking_config=types.ThinkingConfig(
                    include_thoughts=True
                )
            )
        ):
            for part in chunk.candidates[0].content.parts:
                if not part.text:
                    continue
                elif part.thought:
                    thoughts += part.text
                else:
                    answer += part.text
        
        # ì¶”ë¡  ê³¼ì •ì—ì„œ ì¶”ê°€ ìë£Œ ìš”ì²­ ì²˜ë¦¬
        if st.session_state.get('dynamic_search', True):
            enhanced_thoughts = process_thinking_requests(thoughts)
            if enhanced_thoughts != thoughts:
                thoughts = enhanced_thoughts
        
        return thoughts.strip(), answer.strip()
        
    except Exception as e:
        return f"ì¶”ë¡  ê³¼ì • ì˜¤ë¥˜: {str(e)}", f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_normal(prompt: str, system_prompt: str) -> str:
    """ì¼ë°˜ ìƒì„± (Flash ëª¨ë¸)"""
    try:
        resp = g_client.models.generate_content(
            model=GEN_MODEL_NORMAL,
            contents=prompt,
            config=types.GenerateContentConfig(
                system_instruction=system_prompt,
                temperature=TEMP,
                top_p=0.8,
                top_k=20,
                max_output_tokens=MAX_TOK
            )
        )
        return resp.text if resp.text is not None else "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI ì…ë ¥ ë¶€ë¶„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if input_mode == "ê°„ë‹¨ ì…ë ¥":
    col1, col2 = st.columns([5, 1])
    with col1:
        query = st.text_area("ì§ˆë¬¸", placeholder="ì˜ˆ) ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ìƒ ì „ì„¸ë³´ì¦ê¸ˆ ë°˜í™˜ ì‹œê¸°?", key="query_input", height=100)
    with col2:
        st.write("")
        st.write("")
        search_button = st.button("ğŸ” ê²€ìƒ‰", type="primary", use_container_width=True)
        
else:
    # ìƒì„¸ ì…ë ¥ ëª¨ë“œ
    st.markdown("### ğŸ“ ìƒì„¸ ì‚¬ë¡€ ì…ë ¥")
    
    col1, col2 = st.columns(2)
    
    with col1:
        when_info = st.text_input("â° ì–¸ì œ", placeholder="2024ë…„ 1ì›” 15ì¼, ê³„ì•½ ë§Œë£Œ 1ê°œì›” ì „")
        where_info = st.text_input("ğŸ“ ì–´ë””ì„œ", placeholder="ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ OOì•„íŒŒíŠ¸")
    
    with col2:
        who_info = st.text_input("ğŸ‘¥ ëˆ„ê°€", placeholder="ì„ì°¨ì¸ A, ì„ëŒ€ì¸ B")
        what_info = st.text_input("â“ ë¬´ì—‡ì„", placeholder="ì „ì„¸ë³´ì¦ê¸ˆ ë°˜í™˜ ìš”êµ¬")
    
    main_question = st.text_area("ğŸ“‹ ìƒì„¸ ìƒí™© ë° ì§ˆë¬¸", 
                                placeholder="ê³„ì•½ ë§Œë£Œ í›„ ë³´ì¦ê¸ˆì„ ëŒë ¤ë°›ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ ë²•ì  ì¡°ì¹˜ë¥¼ ì·¨í•  ìˆ˜ ìˆë‚˜ìš”?",
                                height=120)
    
    other_info = st.text_area("ğŸ“ ê¸°íƒ€ ì°¸ê³ ì‚¬í•­", 
                             placeholder="íŠ¹ì•½ì‚¬í•­, ê´€ë ¨ ì„œë¥˜, ê¸°íƒ€ ì¤‘ìš” ì •ë³´",
                             height=80)
    
    # êµ¬ì¡°í™”ëœ ì§ˆë¬¸ ìƒì„±
    query_parts = []
    if when_info: query_parts.append(f"ì‹œì : {when_info}")
    if where_info: query_parts.append(f"ì¥ì†Œ: {where_info}")
    if who_info: query_parts.append(f"ë‹¹ì‚¬ì: {who_info}")
    if what_info: query_parts.append(f"í–‰ìœ„: {what_info}")
    if main_question: query_parts.append(f"ì§ˆë¬¸: {main_question}")
    if other_info: query_parts.append(f"ê¸°íƒ€: {other_info}")
    
    query = "\n".join(query_parts)
    
    search_button = st.button("ğŸ” ê²€ìƒ‰", type="primary", use_container_width=True)

# ê²€ìƒ‰ ë²„íŠ¼ ì²˜ë¦¬
if search_button and query.strip():
    st.session_state.search_query = query
    st.session_state.should_search = True
    st.session_state.thinking_requests = []

# ì´ë¦„ì´ ìˆì§€ë§Œ ë°ì´í„°ì— ì—†ëŠ” ë²•ë ¹Â·íŒë¡€ ê²½ê³ 
if query:
    missing = [w for w in re.findall(r"\w+ë²•", query) if w not in NAME2ID]
    if missing:
        st.warning(f"ë°ì´í„°ì— ì—†ëŠ” ë²•ë ¹: {', '.join(missing)}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.session_state.should_search and st.session_state.search_query:
    search_query = st.session_state.search_query
    st.info(f"**ì§ˆë¬¸:** {search_query[:200]}..." if len(search_query) > 200 else f"**ì§ˆë¬¸:** {search_query}")

    with st.spinner("ğŸ” ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
        docs = retrieve(search_query)
        
        # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ í‘œì‹œ (ì •í™•í•œ ë¶„ë¥˜)
        law_docs = [d for d in docs if is_law_document(d["id"], d["meta"])]
        prec_docs = [d for d in docs if not is_law_document(d["id"], d["meta"])]
        
        st.info(f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ: ë²•ë ¹ {len(law_docs)}ê±´, íŒë¡€ {len(prec_docs)}ê±´")
        
        prompt = build_prompt_improved(search_query, docs)
        
        # Think ëª¨ë“œì— ë”°ë¥¸ ìƒì„±
        is_think_mode = think_mode.startswith("Think")
        system_prompt = SYSTEM_PROMPT_THINK if is_think_mode else SYSTEM_PROMPT_NON_THINK
        
        if is_think_mode:
            thinking_process, final_answer = generate_with_thinking(prompt, system_prompt)
            body = final_answer
        else:
            body = generate_normal(prompt, system_prompt)
            thinking_process = ""
        
        # í›„ì²˜ë¦¬
        body = remove_source_section(body)
        footnote_sources = extract_footnote_sources(body)
        body = convert_to_html_footnotes(body)
        body = sanitize_html(body)
        body = filter_hallucinated(body)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ“‹ ë‹µë³€")
    st.markdown(body, unsafe_allow_html=True)
    
    # ê°ì£¼ ë Œë”ë§
    if footnote_sources:
        footnotes_html = render_footnotes_section(footnote_sources)
        st.markdown(footnotes_html, unsafe_allow_html=True)

    # Think ëª¨ë“œì¼ ë•Œë§Œ ì¶”ë¡  ê³¼ì • í‘œì‹œ
    if is_think_mode and thinking_process:
        with st.expander("ğŸ§  AI ìƒì„¸ ì¶”ë¡  ê³¼ì •", expanded=False):
            # ì¶”ë¡  ê³¼ì •ì„ ì„¹ì…˜ë³„ë¡œ ë‚˜ëˆ„ì–´ í‘œì‹œ
            thinking_sections = thinking_process.split('\n\n')
            for i, section in enumerate(thinking_sections, 1):
                if section.strip():
                    st.markdown(f"**ğŸ”„ ì¶”ë¡  ë‹¨ê³„ {i}**")
                    st.markdown(sanitize_html(section.strip()), unsafe_allow_html=True)
                    st.markdown("---")

    # â”€â”€ ì°¸ê³  ë¬¸ì„œ (ì •í™•í•œ ë¶„ë¥˜ë¡œ í‘œì‹œ) â”€â”€
    with st.expander("ğŸ” ì°¸ê³  ë¬¸ì„œ ë³´ê¸°"):
        if law_docs:
            st.markdown("#### ğŸ“œ ë²•ë ¹")
            for i, d in enumerate(law_docs, 1):
                pid = d["meta"].get("parent_id", d["id"])
                title = d["meta"].get("title", pid)
                snippet = d["text"][:300].replace("\n", " ")

                if st.button(f"ğŸ“„ [{i}] {title}", key=f"law_btn_{pid}_{i}"):
                    st.session_state[f"show_law_{pid}"] = not st.session_state.get(f"show_law_{pid}", False)

                if st.session_state.get(f"show_law_{pid}", False):
                    data = load_json(pid)
                    if data:
                        st.json(data, expanded=False)
                    else:
                        st.warning("ì›ë³¸ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                st.markdown(f"<span style='font-size:0.9rem;color:#666'>{snippet}...</span>", unsafe_allow_html=True)
        
        if prec_docs:
            st.markdown("#### âš–ï¸ íŒë¡€")
            for i, d in enumerate(prec_docs, 1):
                pid = d["meta"].get("parent_id", d["id"])
                title = d["meta"].get("title", pid)
                snippet = d["text"][:300].replace("\n", " ")

                if st.button(f"ğŸ“„ [{i}] {title}", key=f"prec_btn_{pid}_{i}"):
                    st.session_state[f"show_prec_{pid}"] = not st.session_state.get(f"show_prec_{pid}", False)

                if st.session_state.get(f"show_prec_{pid}", False):
                    data = load_json(pid)
                    if data:
                        st.json(data, expanded=False)
                    else:
                        st.warning("ì›ë³¸ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                st.markdown(f"<span style='font-size:0.9rem;color:#666'>{snippet}...</span>", unsafe_allow_html=True)

    # ê²€ìƒ‰ ì™„ë£Œ í›„ í”Œë˜ê·¸ ì´ˆê¸°í™”
    st.session_state.should_search = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‘¸í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.markdown(
    "<div style='text-align:center;color:#888;font-size:0.85rem'>"
    "Made with Streamlit Â· Gemini 2.5 Flash Â· ChromaDB<br/>"
    "âš ï¸ AIê°€ ìƒì„±í•œ ë‹µë³€ì´ë¯€ë¡œ ì‹¤ì œ ë²•ë¥  ìë¬¸ì€ ì „ë¬¸ê°€ì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.<br/>"
    "âš  AI can make mistakes. Please verify the information with a reliable source."
    "</div>",
    unsafe_allow_html=True
)