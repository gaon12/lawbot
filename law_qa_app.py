#!/usr/bin/env python3
"""
ğŸ“œ Streamlit â€“ ë²•ë ¹Â·íŒë¡€ Q&A (JSON ë¯¸ë¦¬ë³´ê¸°Â·í™˜ê° ë°©ì§€Â·ê°ì£¼ êµì •Â·COT ë…¸ì¶œ)

ì„¤ì¹˜:  pip install -U streamlit chromadb google-genai python-dotenv
ì‹¤í–‰:  streamlit run law_qa_app.py
"""
from __future__ import annotations
import os, re, html, json, sqlite3, textwrap, time
from pathlib import Path
from typing import List, Dict, Any, Tuple

import streamlit as st
from streamlit.runtime.scriptrunner import add_script_run_ctx
from dotenv import load_dotenv
from google import genai          # type: ignore
import chromadb                   # type: ignore
from chromadb.config import Settings
from google.genai import types
from google.genai.types import EmbedContentConfig

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ê°’ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    raise RuntimeError("âš ï¸  .env íŒŒì¼ì— GEMINI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")

CHROMA_DIR   = "./data/ChromaLegal"
COL_LAW      = "laws"
COL_PREC     = "precs"
EMBED_MODEL  = "gemini-embedding-exp-03-07"
GEN_MODEL    = "gemini-2.5-flash"
TOP_K        = 8
TEMP         = 0.2
MAX_TOK      = 65536
DB_PATH      = "./data/laws/laws.db"
PRE_LAW_DIR  = Path("./data/laws/preprocess")
PRE_PREC_DIR = Path("./data/precs/preprocess")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í´ë¼ì´ì–¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
g_client = genai.Client(api_key=API_KEY)

ch_set  = Settings(is_persistent=True,
                   persist_directory=CHROMA_DIR,
                   anonymized_telemetry=False)
ch_cli  = chromadb.PersistentClient(settings=ch_set)
col_law = ch_cli.get_or_create_collection(COL_LAW)
col_prec= ch_cli.get_or_create_collection(COL_PREC)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Streamlit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config("ğŸ“œ ë²•ë ¹Â·íŒë¡€ Q&A", "ğŸ“œ", layout="wide")
st.markdown("<h1 style='margin-top:0'>ğŸ“œ ë²•ë ¹Â·íŒë¡€ ê¸°ë°˜ Q&A</h1>",
            unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'search_query' not in st.session_state:
    st.session_state.search_query = ""
if 'should_search' not in st.session_state:
    st.session_state.should_search = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False, ttl="1d")
def embed_text(txt: str) -> List[float]:
    """Gemini ì„ë² ë”©"""
    try:
        res = g_client.models.embed_content(
            model=EMBED_MODEL,
            contents=txt,
            config=EmbedContentConfig(
                task_type="RETRIEVAL_DOCUMENT",
                output_dimensionality=3072,
            )
        )
        return res.embeddings[0].values  # type: ignore
    except Exception as e:
        st.error(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
        return []


def _query(col, v) -> List[Dict[str, Any]]:
    if not v:  # ë¹ˆ ì„ë² ë”© ì²˜ë¦¬
        return []
    r = col.query(query_embeddings=[v],
                  n_results=TOP_K,
                  include=["documents", "metadatas", "distances"])
    out = []
    for i in range(len(r["ids"][0])):
        out.append({
            "id"   : r["ids"][0][i],
            "text" : r["documents"][0][i],
            "meta" : r["metadatas"][0][i],
            "score": r["distances"][0][i],
        })
    return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë°ì´í„° ë§¤í•‘ êµ¬ì¶• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False)
def build_name_map() -> Dict[str, str]:
    """ë²•ë ¹Â·íŒë¡€ 'ì œëª© â†’ parent_id' ë§¤í•‘"""
    mp: Dict[str, str] = {}
    for p in PRE_LAW_DIR.glob("*.json"):
        try:
            with p.open(encoding="utf-8") as f:
                title = json.load(f).get("title") or p.stem
            mp[title] = p.stem
        except Exception:
            continue
    for p in PRE_PREC_DIR.glob("*.json"):
        try:
            with p.open(encoding="utf-8") as f:
                title = json.load(f).get("title") or p.stem
            mp[title] = p.stem
        except Exception:
            continue
    return mp

NAME2ID = build_name_map()

@st.cache_data(show_spinner=False)
def valid_ids_from_db() -> set[str]:
    """ì¡´ì¬í•˜ëŠ” parent_id ì§‘í•©"""
    ids: set[str] = set()
    try:
        with sqlite3.connect(DB_PATH) as conn:
            ids.update(r[0] for r in conn.execute("SELECT law_id FROM laws"))
            ids.update(r[0] for r in conn.execute("SELECT prec_id FROM precedents"))
    except Exception:
        pass
    return ids

VALID_IDS = valid_ids_from_db()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í…ìŠ¤íŠ¸Â·JSON ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_json(parent_id: str) -> Dict[str, Any] | None:
    try:
        law_file = PRE_LAW_DIR / f"{parent_id}.json"
        if law_file.exists():
            return json.load(law_file.open("r", encoding="utf-8"))
        prec_file = PRE_PREC_DIR / f"{parent_id}.json"
        if prec_file.exists():
            return json.load(prec_file.open("r", encoding="utf-8"))
    except Exception:
        pass
    return None


def json_to_fulltext(data: Dict[str, Any]) -> str:
    """JSON â†’ ë³¸ë¬¸ ì „ì²´ ë¬¸ìì—´"""
    if "articles" in data:                         # ë²•ë ¹
        return "\n".join(a["text"] for a in data["articles"])
    if "judgement" in data:                        # íŒë¡€
        return data["judgement"]
    return ""


def sanitize_html(raw: str) -> str:
    """ë¶ˆí•„ìš” HTML íƒœê·¸ ì°¨ë‹¨"""
    allowed = {"sup", "sub", "span", "br", "b", "strong", "i", "em", "table", "tr", "td", "th", "thead", "tbody"}
    return re.sub(
        r"</?([a-zA-Z0-9]+)[^>]*>",
        lambda m: m.group(0) if m.group(1).lower() in allowed
        else html.escape(m.group(0)),
        raw,
    )


def filter_hallucinated(txt: str) -> str:
    """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” parent_idë¥¼ [INVALID-â€¦]ë¡œ ì¹˜í™˜"""
    pat = r"(LAW|PREC)_([0-9]+)"
    def repl(m):
        pid = m.group(2)
        if pid in VALID_IDS:
            return m.group(0)
        return f"[INVALID-{pid}]"
    return re.sub(pat, repl, txt)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ COT(think íƒœê·¸) ë° ê°ì£¼ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
THINK_RE = re.compile(r"<think(\d+)>(.*?)</think\1>", re.S)
FINALANSWER_RE = re.compile(r"<finalanswer>(.*?)</finalanswer>", re.S)
FOOT_RE  = re.compile(r"\[\^\s*([0-9]+)\s*\]")

def extract_thinking_process(text: str) -> Tuple[str, List[Tuple[int, str]], str]:
    """ì¶”ë¡  ê³¼ì •, ìµœì¢… ë‹µë³€ ë¶„ë¦¬"""
    # Think ë¸”ë¡ë“¤ ì¶”ì¶œ
    think_matches = THINK_RE.findall(text)
    thinking_steps = [(int(num), content.strip()) for num, content in think_matches]
    
    # Final answer ì¶”ì¶œ
    final_match = FINALANSWER_RE.search(text)
    final_answer = final_match.group(1).strip() if final_match else ""
    
    # ì›ë³¸ì—ì„œ íƒœê·¸ë“¤ ì œê±°í•œ í…ìŠ¤íŠ¸
    cleaned = THINK_RE.sub("", text)
    cleaned = FINALANSWER_RE.sub("", cleaned)
    
    return cleaned, thinking_steps, final_answer

def convert_to_html_footnotes(text: str) -> str:
    """ê°ì£¼ë¥¼ Streamlit í˜¸í™˜ HTMLë¡œ ë³€í™˜ (ì¶œì²˜ ì„¹ì…˜ ì œì™¸)"""
    # ì¶œì²˜ ì„¹ì…˜ ì°¾ê¸°
    source_section_match = re.search(r'(## ì¶œì²˜\s*\n.*?)(?=\n##|\Z)', text, re.S)
    
    if source_section_match:
        # ì¶œì²˜ ì„¹ì…˜ ì´ì „ ë¶€ë¶„ë§Œ ë³€í™˜
        before_sources = text[:source_section_match.start()]
        source_section = source_section_match.group(0)
        after_sources = text[source_section_match.end():]
        
        # ë³¸ë¬¸ì˜ ê°ì£¼ë§Œ HTMLë¡œ ë³€í™˜
        def footnote_repl(match):
            num = match.group(1)
            return f'<sup><a href="#footnote-{num}" style="text-decoration:none; color:#007bff;">[{num}]</a></sup>'
        
        converted_before = re.sub(r'\[\^(\d+)\]', footnote_repl, before_sources)
        
        # ì¶œì²˜ ì„¹ì…˜ì€ ë³€í™˜í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ìœ ì§€
        return converted_before + source_section + after_sources
    else:
        # ì¶œì²˜ ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ì „ì²´ ë³€í™˜
        def footnote_repl(match):
            num = match.group(1)
            return f'<sup><a href="#footnote-{num}" style="text-decoration:none; color:#007bff;">[{num}]</a></sup>'
        
        return re.sub(r'\[\^(\d+)\]', footnote_repl, text)

def render_footnotes_section(footnote_sources: List[Tuple[int, str]]) -> str:
    """ê°ì£¼ ì„¹ì…˜ì„ HTMLë¡œ ë Œë”ë§"""
    if not footnote_sources:
        return ""
    
    footnotes_html = []
    for num, content in footnote_sources:
        footnotes_html.append(
            f'<div id="footnote-{num}" style="margin-bottom: 8px;">'
            f'<sup><strong>[{num}]</strong></sup> '
            f'<span style="margin-left: 4px;">{content}</span>'
            f'</div>'
        )
    return '<div style="border-top: 1px solid #ddd; margin-top: 20px; padding-top: 15px;">' + \
           '<h4>ğŸ“š ê°ì£¼</h4>' + \
           ''.join(footnotes_html) + '</div>'

def extract_footnote_sources(text: str) -> List[Tuple[int, str]]:
    """ê°ì£¼ ì†ŒìŠ¤ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
    sources = []
    
    # ## ì¶œì²˜ ì„¹ì…˜ ì°¾ê¸°
    source_section_match = re.search(r'## ì¶œì²˜\s*\n(.*?)(?=\n##|\n\*\*|\Z)', text, re.S)
    if not source_section_match:
        return sources
    
    source_content = source_section_match.group(1)
    lines = source_content.split('\n')
    
    for line in lines:
        line = line.strip()
        if line.startswith('[^') and ']' in line:
            # ê°ì£¼ ì‹œì‘
            match = re.match(r'\[\^(\d+)\]\s*(.*)', line)
            if match:
                num = int(match.group(1))
                content = match.group(2)
                sources.append((num, content))
    
    return sources

def is_reasoning_model_response(text: str) -> bool:
    """ì¶”ë¡  ëª¨ë¸ì˜ ì‘ë‹µì¸ì§€ í™•ì¸"""
    return bool(THINK_RE.search(text) or FINALANSWER_RE.search(text))

def generate_multi_turn_reasoning(query: str, docs: List[Dict[str, Any]]) -> Tuple[str, List[Tuple[int, str]]]:
    """Gemini ê³µì‹ ë©€í‹°í„´ APIë¥¼ ì‚¬ìš©í•œ ì²´ê³„ì  ì¶”ë¡ """
    thinking_steps = []
    
    try:
        # ì±„íŒ… ì„¸ì…˜ ìƒì„±
        chat = g_client.chats.create(model=GEN_MODEL)
        
        # Turn 1: ì§ˆë¬¸ ë¶„ì„ ë° ìŸì  íŒŒì•…
        step1_prompt = f"""
        ì§ˆë¬¸: {query}
        
        ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:
        1. í•µì‹¬ ìŸì  3ê°œ ì´ë‚´ë¡œ ì •ë¦¬
        2. í•„ìš”í•œ ë²•ë ¹ ì˜ì—­ ì‹ë³„
        3. ì¶”ê°€ ê²€í†  í•„ìš” ì‚¬í•­ ëª…ì‹œ
        
        ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
        """
        
        step1_resp = chat.send_message(step1_prompt)
        step1_text = step1_resp.text if step1_resp.text is not None else "ìŸì  ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        thinking_steps.append((1, "ìŸì  ë¶„ì„: " + step1_text))
        
        # Turn 2: ë²•ë ¹ ë¶„ì„
        step2_prompt = f"""
        ê´€ë ¨ ìë£Œ: {docs[:4]}  
        
        ìœ„ ê´€ë ¨ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²•ë ¹ì„ ìƒì„¸ ë¶„ì„í•˜ì„¸ìš”:
        1. ì ìš© ì¡°ë¬¸ í™•ì¸
        2. êµ¬ì„±ìš”ê±´ ë¶„ì„
        3. í•´ì„ìƒ ìŸì  ì •ë¦¬
        """
        
        step2_resp = chat.send_message(step2_prompt)
        step2_text = step2_resp.text if step2_resp.text is not None else "ë²•ë ¹ ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        thinking_steps.append((2, "ë²•ë ¹ ë¶„ì„: " + step2_text))
        
        # Turn 3: íŒë¡€ ë¶„ì„
        prec_docs = [d for d in docs if 'PREC_' in d.get('id', '')]
        step3_prompt = f"""
        íŒë¡€ ìë£Œ: {prec_docs}
        
        íŒë¡€ë¥¼ ë¶„ì„í•˜ì—¬:
        1. ìœ ì‚¬ ì‚¬ì•ˆ íŒë¡€ ì‹ë³„
        2. íŒì‹œ ìš”ì§€ ì •ë¦¬
        3. êµ¬ë³„ë˜ëŠ” ì‚¬ì‹¤ê´€ê³„ ê²€í† 
        """
        
        step3_resp = chat.send_message(step3_prompt)
        step3_text = step3_resp.text if step3_resp.text is not None else "íŒë¡€ ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        thinking_steps.append((3, "íŒë¡€ ë¶„ì„: " + step3_text))
        
        # Turn 4: ì¢…í•© ê²°ë¡ 
        final_prompt = f"""
        ì§€ê¸ˆê¹Œì§€ì˜ ë¶„ì„ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
        
        ë°˜ë“œì‹œ ë‹¤ìŒ êµ¬ì¡°ë¥¼ ì¤€ìˆ˜í•˜ì„¸ìš”:
        
        ã€3ì¤„ ìš”ì•½ã€‘
        1. [í•µì‹¬ ìŸì  í•œ ì¤„]
        2. [ì ìš© ë²•ë ¹/íŒë¡€ í•œ ì¤„] 
        3. [ê²°ë¡  ë°©í–¥ í•œ ì¤„]

        **I. ìŸì  ì •ë¦¬**
        **II. ê´€ë ¨ ë²•ë ¹ ë¶„ì„**  
        **III. íŒë¡€ ê²€í† **
        **IV. ë²•ë¦¬ì  ë¶„ì„**
        
        ã€ì˜ˆìƒ ê²°ê³¼/í˜•ëŸ‰ã€‘
        - êµ¬ì²´ì  ì˜ˆìƒ ê²°ê³¼ ì œì‹œ
        
        ## ì¶œì²˜
        [^1] ë²•ë ¹ëª…/íŒë¡€ + í•µì‹¬ ë‚´ìš©
        [^2] ë²•ë ¹ëª…/íŒë¡€ + í•µì‹¬ ë‚´ìš©
        """
        
        final_resp = chat.send_message(final_prompt)
        final_text = final_resp.text if final_resp.text is not None else "ìµœì¢… ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        thinking_steps.append((4, "ìµœì¢… ë‹µë³€ ìƒì„± ì™„ë£Œ"))
        
        return final_text, thinking_steps
        
    except Exception as e:
        error_text = f"ë©€í‹°í„´ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        thinking_steps.append((1, error_text))
        return error_text, thinking_steps

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²€ìƒ‰ & í”„ë¡¬í”„íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def retrieve(q: str) -> List[Dict[str, Any]]:
    """â‘  ëª…ì‹œì  ì´ë¦„ í˜¸ì¶œ â†’ ì›ë¬¸, â‘¡ ì„ë² ë”© ê²€ìƒ‰"""
    explicit_docs: List[Dict[str, Any]] = []
    for name, pid in NAME2ID.items():
        if name in q:
            data = load_json(pid)
            if data:
                explicit_docs.append({
                    "id": pid,
                    "text": json_to_fulltext(data),
                    "meta": {"parent_id": pid, "title": name},
                    "score": 0.0,
                })

    v    = embed_text(q)
    docs = _query(col_law, v) + _query(col_prec, v)
    docs = explicit_docs + docs
    docs.sort(key=lambda d: d["score"])
    return docs[:TOP_K]

def get_additional_documents(requested_laws: List[str]) -> List[Dict[str, Any]]:
    """LLMì´ ìš”ì²­í•œ ì¶”ê°€ ë²•ë ¹/íŒë¡€ ì „ì²´ ì œê³µ"""
    additional_docs = []
    for law_name in requested_laws:
        if law_name in NAME2ID:
            pid = NAME2ID[law_name]
            data = load_json(pid)
            if data:
                additional_docs.append({
                    "id": pid,
                    "text": json_to_fulltext(data),
                    "meta": {"parent_id": pid, "title": law_name},
                    "score": 0.0,
                })
    return additional_docs

def build_prompt(q: str, docs: List[Dict[str, Any]]) -> Tuple[str, str]:
    """LLMì— ë„£ì„ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
    ctx, id_set = [], set[str]()
    for i, d in enumerate(docs, 1):
        title = d["meta"].get("title", d["id"])
        ctx.append(f"[{i}] ({title}) {d['text']}")
        id_set.add(d["meta"]["parent_id"])
    joined = "\n\n".join(ctx)
    return f"[ì§ˆë¬¸]\n{q}\n\n[ìë£Œ]\n{joined}", ", ".join(sorted(id_set))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT_REASONING = textwrap.dedent("""
    ë„ˆëŠ” í•œêµ­ì˜ **ë²•ë ¹ê³¼ íŒë¡€**ë¥¼ ë™ì‹œì— ì°¸ê³ í•˜ì—¬ ë²•ë¥  ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì „ë¬¸ AIì´ë‹¤.

    ## ë‹µë³€ êµ¬ì¡° (í•„ìˆ˜ ì¤€ìˆ˜):
    **ã€3ì¤„ ìš”ì•½ã€‘**
    1. [í•µì‹¬ ìŸì  í•œ ì¤„]
    2. [ì ìš© ë²•ë ¹/íŒë¡€ í•œ ì¤„] 
    3. [ê²°ë¡  ë°©í–¥ í•œ ì¤„]

    **I. ìŸì  ì •ë¦¬**
    **II. ê´€ë ¨ ë²•ë ¹ ë¶„ì„**
    **III. íŒë¡€ ê²€í† **  
    **IV. ë²•ë¦¬ì  ë¶„ì„**
    
    **ã€ì˜ˆìƒ ê²°ê³¼/í˜•ëŸ‰ã€‘**
    - ë¯¼ì‚¬: ì†í•´ë°°ìƒì•¡, ìŠ¹ì†Œ ê°€ëŠ¥ì„± ë“±
    - í˜•ì‚¬: ì˜ˆìƒ í˜•ëŸ‰, ê¸°ì†Œ ê°€ëŠ¥ì„± ë“±
    - í–‰ì •: ì²˜ë¶„ ì ë²•ì„±, êµ¬ì œ ë°©ë²• ë“±

    ## ì„œì‹ ë° êµ¬ì¡°í™” ì§€ì¹¨:
    1) **í•˜ìœ„ ì œëª© í™œìš©**: ê° ë¶„ì„ ë‹¨ê³„ì—ì„œ ### ì†Œì œëª© ì‚¬ìš©
       ì˜ˆ: ### êµ¬ì„±ìš”ê±´ ê²€í† , ### ìœ„ë²•ì„± íŒë‹¨, ### ì±…ì„ ê²€í† 

    2) **í‘œ í™œìš© (ë¹„êµ ì‹œ)**: 
       - ë²•ë ¹ vs íŒë¡€ ë¹„êµ
       - êµ¬ì„±ìš”ê±´ë³„ í•´ë‹¹ ì—¬ë¶€
       - ìœ ì‚¬ íŒë¡€ ë¹„êµ ë¶„ì„

    3) **ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°**: ë³µí•©ì  ìŸì ì€ ë²ˆí˜¸ë‚˜ ë¶ˆë¦¿ í¬ì¸íŠ¸ í™œìš©

    ## ë‹¨ê³„ë³„ ì¶”ë¡  ê³¼ì • (í•„ìˆ˜):
    1) **ë°˜ë“œì‹œ** ë‹µë³€ ì „ì— ë‹¨ê³„ë³„ ì¶”ë¡ ì„ ìˆ˜í–‰í•œë‹¤:
       - <think1>ì§ˆë¬¸ ë¶„ì„ ë° ìŸì  íŒŒì•…</think1>
       - <think2>ê´€ë ¨ ë²•ë ¹ ë° íŒë¡€ ê²€í† </think2>
       - <think3>ë²•ë¦¬ì  ë¶„ì„ ë° í•´ì„</think3>
       - <think4>ê²°ë¡  ë„ì¶œ ë° ê²€ì¦</think4>
       - í•„ìš”ì‹œ <think5>, <think6> ë“± ì¶”ê°€ ë‹¨ê³„ ìˆ˜í–‰
    
    2) ëª¨ë“  ì¶”ë¡ ì´ ì™„ë£Œëœ í›„ **ìµœì¢… ë‹µë³€**ì„ ì‘ì„±í•œë‹¤:
       <finalanswer>
       [ìœ„ì˜ ë‹µë³€ êµ¬ì¡°ì— ë”°ë¥¸ ì™„ì „í•œ ë‹µë³€]
       </finalanswer>

    ## ê°ì£¼ ì‘ì„± ê·œì¹™:
    - ê°ì£¼ëŠ” [^1], [^2] í˜•íƒœë¡œ ì‘ì„±
    - ê°ì£¼ ë‚´ìš©ì€ ë‹µë³€ ë§ˆì§€ë§‰ '## ì¶œì²˜' ì„¹ì…˜ì— ì •ë¦¬
    - ê°ì£¼ ë²ˆí˜¸ëŠ” 1ë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ì¦ê°€
    - ê° ê°ì£¼ ë’¤ì—ëŠ” ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆ ì¶”ê°€

    ## ì£¼ì˜ì‚¬í•­:
    - ë²•ë¥  ìë¬¸ì´ ì•„ë‹Œ ì¼ë°˜ì  ì •ë³´ ì œê³µì„ì„ í•„ìš”ì‹œ ëª…ì‹œ
    - ì œê³µëœ [ìë£Œ]ì˜ ë²”ìœ„ì—ì„œë§Œ ì¸ìš©
    - í™•ì‹¤í•˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  í•œê³„ë¥¼ ëª…ì‹œ
""")

SYSTEM_PROMPT_STEP1 = textwrap.dedent("""
    ë„ˆëŠ” í•œêµ­ì˜ **ë²•ë ¹ê³¼ íŒë¡€**ë¥¼ ì°¸ê³ í•˜ì—¬ ë²•ë¥  ì§ˆë¬¸ì„ ë¶„ì„í•˜ëŠ” AIì´ë‹¤.
    
    ì£¼ì–´ì§„ ì§ˆë¬¸ê³¼ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ë¼:
    
    1. **ì§ˆë¬¸ì˜ í•µì‹¬ ìŸì ì„ íŒŒì•…**í•˜ë¼
    2. **ê´€ë ¨ ë²•ë ¹ê³¼ íŒë¡€ë¥¼ ì‹ë³„**í•˜ë¼  
    3. **ì¶”ê°€ë¡œ í•„ìš”í•œ ë²•ë ¹ì´ë‚˜ íŒë¡€ê°€ ìˆë‹¤ë©´ ëª…ì‹œ**í•˜ë¼
    
    ì‘ë‹µ í˜•ì‹:
    ## ìŸì  ë¶„ì„
    [ì§ˆë¬¸ì˜ í•µì‹¬ ìŸì  ì •ë¦¬]
    
    ## ê´€ë ¨ ìë£Œ ê²€í† 
    [ì œê³µëœ ìë£Œ ì¤‘ ê´€ë ¨ì„±ì´ ë†’ì€ ê²ƒë“¤]
    
    ## ì¶”ê°€ í•„ìš” ìë£Œ
    [í•„ìš”í•œ ê²½ìš°] ì¶”ê°€ í•„ìš”: [ë²•ë ¹ëª…1], [ë²•ë ¹ëª…2]
""")

SYSTEM_PROMPT_STEP2 = textwrap.dedent("""
    ë„ˆëŠ” í•œêµ­ì˜ **ë²•ë ¹ê³¼ íŒë¡€**ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²•ë¥  ë‹µë³€ì„ ì‘ì„±í•˜ëŠ” ì „ë¬¸ AIì´ë‹¤.
    
    ì´ì „ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ì™„ì „í•œ ë²•ë¥  ë‹µë³€ì„ ì‘ì„±í•˜ë¼:
    
    ## ë‹µë³€ êµ¬ì¡° (í•„ìˆ˜):
    **ã€3ì¤„ ìš”ì•½ã€‘**
    1. [í•µì‹¬ ìŸì  í•œ ì¤„]
    2. [ì ìš© ë²•ë ¹/íŒë¡€ í•œ ì¤„] 
    3. [ê²°ë¡  ë°©í–¥ í•œ ì¤„]

    **I. ìŸì  ì •ë¦¬**
    **II. ê´€ë ¨ ë²•ë ¹ ë¶„ì„**  
    **III. íŒë¡€ ê²€í† **
    **IV. ë²•ë¦¬ì  ë¶„ì„**
    
    **ã€ì˜ˆìƒ ê²°ê³¼/í˜•ëŸ‰ã€‘**
    [êµ¬ì²´ì  ì˜ˆìƒ ê²°ê³¼]
    
    ## ì¶œì²˜
    [^1] ë²•ë ¹ëª…/íŒë¡€ + í•µì‹¬ ë‚´ìš©
    [^2] ë²•ë ¹ëª…/íŒë¡€ + í•µì‹¬ ë‚´ìš©
    
    ## ê·œì¹™:
    - í•œêµ­ì–´ '~ì´ë‹¤'ì²´ ì‚¬ìš©
    - ê·¼ê±° ë¬¸ì¥ë§ˆë‹¤ ê°ì£¼ [^n] í‘œê¸° (1ë¶€í„° ìˆœì°¨)
    - ê°ì£¼ëŠ” ë§ˆì§€ë§‰ '## ì¶œì²˜' ì„¹ì…˜ì— ì •ë¦¬
    - ê° ê°ì£¼ ë’¤ì—ëŠ” ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆ ì¶”ê°€
    - ì œê³µëœ ìë£Œ ë²”ìœ„ì—ì„œë§Œ ì¸ìš©
    - ê°€ìƒì˜ ì„¸ê³„ ë˜ëŠ” íƒ€êµ­ì˜ ì‚¬ë¡€ì´ë”ë¼ë„, í•œêµ­ì˜ ë²•ë¥ ê³¼ íŒë¡€ë¥¼ ê°€ì§€ê³  ë¶„ì„
""")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI ë™ì‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì…ë ¥ í¼ê³¼ ë²„íŠ¼
col1, col2 = st.columns([5, 1])
with col1:
    query = st.text_area("ì§ˆë¬¸", placeholder="ì˜ˆ) ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•ìƒ ì „ì„¸ë³´ì¦ê¸ˆ ë°˜í™˜ ì‹œê¸°?", key="query_input")
with col2:
    st.write("")  # ë²„íŠ¼ ìœ„ì¹˜ ì¡°ì •ìš©
    st.write("")
    search_button = st.button("ğŸ” ê²€ìƒ‰", type="primary", use_container_width=True)

# ê²€ìƒ‰ ë²„íŠ¼ì´ í´ë¦­ë˜ì—ˆì„ ë•Œë§Œ ì²˜ë¦¬
if search_button and query:
    st.session_state.search_query = query
    st.session_state.should_search = True

# ì´ë¦„ì´ ìˆì§€ë§Œ ë°ì´í„°ì— ì—†ëŠ” ë²•ë ¹Â·íŒë¡€ ê²½ê³ 
if query:
    missing = [w for w in re.findall(r"\w+ë²•", query) if w not in NAME2ID]
    if missing:
        st.warning(f"ë°ì´í„°ì— ì—†ëŠ” ë²•ë ¹: {', '.join(missing)}")

# ì‹¤ì œ ê²€ìƒ‰ ì²˜ë¦¬
if st.session_state.should_search and st.session_state.search_query:
    search_query = st.session_state.search_query
    st.info(f"**ì§ˆë¬¸:** {search_query}")

    # ì¶”ë¡  ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆ
    progress_container = st.container()
    
    with st.spinner("ğŸ” ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
        docs = retrieve(search_query)
        
        # ì²« ë²ˆì§¸ ì‹œë„: ì¼ë°˜ì ì¸ ë°©ì‹ìœ¼ë¡œ ìƒì„±
        prompt, _ids = build_prompt(search_query, docs)
        
        try:
            resp = g_client.models.generate_content(
                model=GEN_MODEL,
                contents=prompt,
                config=types.GenerateContentConfig(
                    system_instruction=SYSTEM_PROMPT_REASONING,
                    temperature=TEMP,
                    top_p=0.8,
                    top_k=20,
                    max_output_tokens=MAX_TOK)
            )

            raw_answer = resp.text if resp.text is not None else "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            thinking_steps = []
            
        except Exception as e:
            raw_answer = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            thinking_steps = [(1, f"ì˜¤ë¥˜: {str(e)}")]
        
        # ì¶”ë¡  ëª¨ë¸ì¸ì§€ í™•ì¸
        if is_reasoning_model_response(raw_answer):
            # ì¶”ë¡  ëª¨ë¸ ì‘ë‹µ ì²˜ë¦¬
            cleaned_text, thinking_steps, final_answer = extract_thinking_process(raw_answer)
            
            # ì¶”ê°€ ìë£Œ ìš”ì²­ ì²˜ë¦¬
            additional_law_requests = re.findall(r"ì¶”ê°€ í•„ìš”:\s*([^,\n]+(?:,\s*[^,\n]+)*)", raw_answer)
            if additional_law_requests:
                requested_laws = [law.strip() for request in additional_law_requests 
                                for law in request.split(',')]
                additional_docs = get_additional_documents(requested_laws)
                if additional_docs:
                    docs.extend(additional_docs)
                    thinking_steps.append((len(thinking_steps) + 1, f"ì¶”ê°€ ìë£Œ í™•ë³´: {', '.join(requested_laws)}"))
                    
                    # ì¶”ê°€ ìë£Œë¡œ ì¬ìƒì„±
                    prompt, _ids = build_prompt(search_query, docs)
                    try:
                        resp = g_client.models.generate_content(
                            model=GEN_MODEL,
                            contents=prompt,
                            config=types.GenerateContentConfig(
                                system_instruction=SYSTEM_PROMPT_REASONING,
                                temperature=TEMP,
                                top_p=0.8,
                                top_k=20,
                                max_output_tokens=MAX_TOK)
                        )
                        raw_answer = resp.text if resp.text is not None else "ì¬ìƒì„± ì‹¤íŒ¨"
                        cleaned_text, new_thinking_steps, final_answer = extract_thinking_process(raw_answer)
                        thinking_steps.extend(new_thinking_steps)
                    except Exception as e:
                        thinking_steps.append((len(thinking_steps) + 1, f"ì¬ìƒì„± ì˜¤ë¥˜: {str(e)}"))

            # ìµœì¢… ë‹µë³€ ì²˜ë¦¬
            body = final_answer if final_answer else cleaned_text
            # ê°ì£¼ ì†ŒìŠ¤ëŠ” ì›ë³¸ì—ì„œ ì¶”ì¶œ
            footnote_sources = extract_footnote_sources(raw_answer)
            
        else:
            # ë¹„ì¶”ë¡  ëª¨ë¸: ë©€í‹°í„´ ì¶”ë¡  ìƒì„±
            st.info("ğŸ”„ ë‹¨ê³„ë³„ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤...")
            body, thinking_steps = generate_multi_turn_reasoning(search_query, docs)
            raw_answer = body  # ì›ë³¸ ë³´ì¡´
            # ê°ì£¼ ì†ŒìŠ¤ëŠ” ì›ë³¸ì—ì„œ ì¶”ì¶œ
            footnote_sources = extract_footnote_sources(raw_answer)
            
        # ê³µí†µ í›„ì²˜ë¦¬
        body = convert_to_html_footnotes(body)
        body = sanitize_html(body)
        body = filter_hallucinated(body)

        reasoning_summary = ""
        try:
            reasoning_summary = (resp.candidates[0].citation_metadata.summary
                               if resp.candidates
                               and resp.candidates[0].citation_metadata else "")
        except:
            pass

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ“‹ ë‹µë³€", unsafe_allow_html=True)
    st.markdown(body, unsafe_allow_html=True)
    
    # ê°ì£¼ ì²˜ë¦¬ - ê°œì„ ëœ ë°©ì‹
    if footnote_sources:
        footnotes_html = render_footnotes_section(footnote_sources)
        st.markdown(footnotes_html, unsafe_allow_html=True)

    # ì¶”ë¡  ê³¼ì • í‘œì‹œ
    if thinking_steps:
        with st.expander("ğŸ§  AI ì¶”ë¡  ê³¼ì • (ì ‘ê¸°/í¼ì¹˜ê¸°)"):
            for step_num, content in thinking_steps:
                st.markdown(f"### ğŸ”„ {step_num}ì°¨ ì¶”ë¡  ì™„ë£Œ")
                st.markdown(sanitize_html(content), unsafe_allow_html=True)
                st.markdown("---")
                
        if reasoning_summary:
            st.write("**ì¶”ë¡  ìš”ì•½:**")
            st.write(reasoning_summary)

    # â”€â”€ ì°¸ê³  ë¬¸ì„œ (JSON ë¯¸ë¦¬ë³´ê¸°) â”€â”€
    with st.expander("ğŸ” ì°¸ê³  ë¬¸ì„œ ë³´ê¸°"):
        for i, d in enumerate(docs, 1):
            pid = d["meta"]["parent_id"]
            title = d["meta"].get("title", pid)
            snippet = d["text"][:400].replace("\n", " ")

            if st.button(f"ğŸ“„ [{i}] {title}", key=f"btn_{pid}"):
                st.session_state[f"show_{pid}"] = not st.session_state.get(
                    f"show_{pid}", False)

            if st.session_state.get(f"show_{pid}", False):
                data = load_json(pid)
                if data:
                    st.json(data, expanded=False)
                else:
                    st.warning("ì›ë³¸ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            st.markdown(f"<span style='font-size:0.9rem;color:#666'>{snippet}...</span>",
                        unsafe_allow_html=True)

    # ê²€ìƒ‰ ì™„ë£Œ í›„ í”Œë˜ê·¸ ì´ˆê¸°í™”
    st.session_state.should_search = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‘¸í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.markdown(
    "<div style='text-align:center;color:#888;font-size:0.85rem'>"
    "Made with Streamlit Â· Gemini Â· ChromaDB.<br/>"
    "AI can make mistakes. Please verify the information with a reliable source."
    "</div>",
    unsafe_allow_html=True
)