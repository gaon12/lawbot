#!/usr/bin/env python3
"""
ðŸ‡°ðŸ‡· ë²•ë ¹(ë²•) + íŒë¡€(prec) DRF API ë¹„ë™ê¸° ìˆ˜ì§‘ê¸°
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. asyncio + aiohttp : ë„¤íŠ¸ì›Œí¬ I/O ì™„ì „ ë¹„ë™ê¸°
2. ThreadPool ì œê±° â†’ GILÂ·ë½ ì´ìŠˆ ê°ì†Œ, ë©”ëª¨ë¦¬ ì‚¬ìš©â†“
3. ë²•ë ¹Â·íŒë¡€ ê³µí†µ íŒŒì´í”„ë¼ì¸ (target ë§¤ê°œë³€ìˆ˜ í•˜ë‚˜ë¡œ ì²˜ë¦¬)
4. aiosqliteë¡œ ë©”ì¸-ë£¨í”„ ì•ˆì—ì„œë„ DB ì—…ì„œíŠ¸ non-blocking
5. tqdm ì„¸ ë‹¨ê³„ ì§„í–‰ ë§‰ëŒ€ ìœ ì§€ (ëª©ë¡ â†’ ë‹¤ìš´ë¡œë“œ â†’ DB)
6. rerequest.jsonì— ëª…ì‹œëœ IDëŠ” ê°•ì œ ìž¬ë‹¤ìš´ë¡œë“œ
"""

import os, math, json, asyncio, aiohttp, aiosqlite
from datetime import datetime, timezone
from typing import List, Tuple, Dict, Any, Optional

from dotenv import load_dotenv
from tqdm.asyncio import tqdm

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ê°’ & ê²½ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
API_KEY      = os.getenv("API_KEY") or exit("âš ï¸  .envì˜ API_KEY ëˆ„ë½")
MAX_CONC     = 32   # ë™ì‹œ ì—°ê²° ìˆ˜
DISPLAY      = 100  # DRF í•œ íŽ˜ì´ì§€ ë‹¹ ê°œìˆ˜
BASE_SEARCH  = "https://www.law.go.kr/DRF/lawSearch.do"
BASE_SERVICE = "https://www.law.go.kr/DRF/lawService.do"

RAW_DIR = "./data/laws/raw"          # ë²•ë ¹ raw
PRE_DIR = "./data/laws/preprocess"
RAW_P  = "./data/precs/raw"          # íŒë¡€ raw
PRE_P  = "./data/precs/preprocess"
DB_PATH = "./data/laws/laws.db"
REREQUEST_PATH = "./rerequest.json"  # ê°•ì œ ê°±ì‹  ëª©ë¡

for p in (RAW_DIR, PRE_DIR, RAW_P, PRE_P, os.path.dirname(DB_PATH)):
    os.makedirs(p, exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ rerequest ëª©ë¡ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_rerequest() -> Tuple[set, set]:
    try:
        with open(REREQUEST_PATH, "r", encoding="utf-8") as f:
            d = json.load(f)
        law_ids  = set(map(str, d.get("law", [])   + d.get("laws", [])))
        prec_ids = set(map(str, d.get("prec", [])  + d.get("precs", [])))
        return law_ids, prec_ids
    except FileNotFoundError:
        return set(), set()
    except Exception as e:
        print(f"âš ï¸  rerequest.json íŒŒì‹± ì˜¤ë¥˜: {e}")
        return set(), set()

RE_LAWS, RE_PRECS = load_rerequest()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DB ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INIT_SQL = {
    "laws": """
        CREATE TABLE IF NOT EXISTS laws (
            law_id      TEXT PRIMARY KEY,
            law_title   TEXT,
            law_abbr    TEXT,
            first_seen  TEXT,
            last_saved  TEXT,
            is_current  INTEGER,
            indexed     INTEGER DEFAULT 0
        );
    """,
    "precs": """
        CREATE TABLE IF NOT EXISTS precedents (
            prec_id     TEXT PRIMARY KEY,
            first_seen  TEXT,
            last_saved  TEXT,
            indexed     INTEGER DEFAULT 0
        );
    """
}

async def init_db():
    async with aiosqlite.connect(DB_PATH) as db:
        # í…Œì´ë¸” ìƒì„±
        for sql in INIT_SQL.values():
            await db.execute(sql)
        await db.commit()

        # ì»¬ëŸ¼ ìžë™ ì¶”ê°€(ì´ë¯¸ ì¡´ìž¬í•œë‹¤ë©´ ë¬´ì‹œ)
        async def ensure_column(table: str, col: str, typ: str):
            rows = [r async for r in await db.execute(f"PRAGMA table_info({table})")]
            col_names = [r[1] for r in rows]  # r[1]ì€ ì»¬ëŸ¼ëª…
            if col not in col_names:
                await db.execute(f"ALTER TABLE {table} ADD COLUMN {col} {typ};")
        await ensure_column("laws",  "law_title", "TEXT")
        await ensure_column("laws",  "law_abbr",  "TEXT")
        await db.commit()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê³µí†µ í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def save_json(path: str, data: Dict[str, Any]) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def collect_text(value, acc: List[str]):
    if value is None: return
    if isinstance(value, str):
        txt = value.strip()
        if txt: acc.append(txt)
    elif isinstance(value, list):
        for v in value: collect_text(v, acc)
    elif isinstance(value, dict):
        for v in value.values(): collect_text(v, acc)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¹„ë™ê¸° HTTP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def fetch_json(session: aiohttp.ClientSession, url: str, params: Dict[str,str], timeout=15):
    async with session.get(url, params=params, timeout=timeout) as resp:
        resp.raise_for_status()
        return await resp.json(content_type=None)

async def get_total(session, target: str) -> int:
    j = await fetch_json(session, BASE_SEARCH, {
        "OC": API_KEY, "target": target, "type": "JSON",
        "display": DISPLAY, "page": 1
    })
    key = "LawSearch" if target=="law" else "PrecSearch"
    return int(j[key]["totalCnt"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì „ì²˜ë¦¬ ê·œì¹™ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def preprocess_law(mst:str, raw:Dict[str,Any]) -> Dict[str,Any]:
    root  = raw.get("ë²•ë ¹", {})
    basic = root.get("ê¸°ë³¸ì •ë³´", {})
    lines : List[str] = []
    # ì£¼ìš” í…ìŠ¤íŠ¸ í•„ë“œ ìˆ˜ì§‘
    collect_text(root.get("ê°œì •ë¬¸", {}).get("ê°œì •ë¬¸ë‚´ìš©"), lines)
    collect_text(root.get("ì œê°œì •ì´ìœ ", {}).get("ì œê°œì •ì´ìœ ë‚´ìš©"), lines)
    collect_text(root.get("ë¶€ì¹™", {}).get("ë¶€ì¹™ë‹¨ìœ„"), lines)
    for cl in root.get("ì¡°ë¬¸", {}).get("ì¡°ë¬¸ë‹¨ìœ„", []):
        collect_text(cl, lines)
    return {
        "mst": mst,
        "law_id": basic.get("ë²•ë ¹ID", ""),
        "title":  basic.get("ë²•ë ¹ëª…_í•œê¸€", ""),
        "abbr":   basic.get("ë²•ë ¹ëª…ì•½ì¹­") or basic.get("ë²•ë ¹ì•½ì¹­ëª…") or "",
        "content": "\n".join(lines)
    }

def preprocess_prec(pid:str, raw:Dict[str,Any]) -> Dict[str,Any]:
    root  = raw.get("PrecService", {})
    lines : List[str] = []
    for k in ("íŒì‹œì‚¬í•­","íŒê²°ìš”ì§€","íŒë¡€ë‚´ìš©"):
        collect_text(root.get(k), lines)
    return {
        "prec_id": root.get("íŒë¡€ì •ë³´ì¼ë ¨ë²ˆí˜¸") or pid,
        "title":   root.get("ì‚¬ê±´ëª…", ""),
        "court":   root.get("ë²•ì›ëª…", ""),
        "content": "\n".join(lines)
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íŒŒì´í”„ë¼ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def collect_master(session, target:str) -> List[Tuple[str,bool]]:
    """target='law' â†’ [(mst,is_current)], target='prec' â†’ [(pid,True)]"""
    total = await get_total(session, target)
    pages = math.ceil(total / DISPLAY)
    out=[]
    desc = "ëª©ë¡(Law)" if target=="law" else "ëª©ë¡(Prec)"
    for page in tqdm(range(1, pages+1), desc=desc, unit="page"):
        res = await fetch_json(session, BASE_SEARCH, {
            "OC": API_KEY, "target": target, "type":"JSON",
            "display": DISPLAY, "page": page
        })
        key   = "law" if target=="law" else "prec"
        items = res["LawSearch" if target=="law" else "PrecSearch"].get(key,[])
        for it in items:
            if target=="law":
                mst = str(it.get("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸","")).strip()
                if mst: out.append((mst, it.get("í˜„í–‰ì—°í˜ì½”ë“œ","")=="í˜„í–‰"))
            else:
                pid = str(it.get("íŒë¡€ì¼ë ¨ë²ˆí˜¸") or it.get("id","")).strip()
                if pid: out.append((pid, True))
    return out

async def worker(item:str, flag:bool, target:str, session:aiohttp.ClientSession) -> Tuple[str,bool,Optional[str],Optional[str]]:
    """
    ë‹¤ìš´ë¡œë“œâ†’ì „ì²˜ë¦¬â†’ì €ìž¥ : (key,is_current,title,abbr)
    target=='law'  â†’ (law_id,flag,title,abbr)
    target=='prec' â†’ (prec_id,flag,None,None)
    """
    raw_dir, pre_dir = (RAW_DIR, PRE_DIR) if target=="law" else (RAW_P, PRE_P)
    raw_p = os.path.join(raw_dir, f"{item}.json")
    pre_p = os.path.join(pre_dir, f"{item}.json")

    # ê°•ì œ ìž¬ë‹¤ìš´ë¡œë“œ ì—¬ë¶€
    force_redl = (item in RE_LAWS) if target=="law" else (item in RE_PRECS)

    # ì´ë¯¸ ì „ì²˜ë¦¬ íŒŒì¼ì´ ìžˆê³ , ê°•ì œ ëª¨ë“œê°€ ì•„ë‹ˆë©´ ì¦‰ì‹œ ë°˜í™˜
    if not force_redl and os.path.exists(pre_p):
        try:
            with open(pre_p, "r", encoding="utf-8") as f:
                data = json.load(f)
            if target=="law":
                return data.get("law_id",""), flag, data.get("title",""), data.get("abbr","")
            else:
                return data.get("prec_id",""), flag, None, None
        except Exception:
            pass  # ì†ìƒ ì‹œ ìž¬ì²˜ë¦¬

    # fetch
    try:
        raw = await fetch_json(session, BASE_SERVICE, {
            "OC": API_KEY, "target": target,
            ("MST" if target=="law" else "ID"): item,
            "type":"JSON"
        })
    except Exception as e:
        print(f"âš ï¸  fetch ì‹¤íŒ¨({item}): {e}")
        return "", flag, None, None
    await asyncio.to_thread(save_json, raw_p, raw)

    # preprocess
    pre = (preprocess_law if target=="law" else preprocess_prec)(item, raw)
    await asyncio.to_thread(save_json, pre_p, pre)

    if target=="law":
        return pre["law_id"], flag, pre["title"], pre["abbr"]
    else:
        return pre["prec_id"], flag, None, None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DB ì—…ì„œíŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def upsert_many(rows, table:str):
    now = datetime.now(timezone.utc).isoformat()
    async with aiosqlite.connect(DB_PATH) as db:
        if table=="laws":
            await db.executemany(
                """INSERT INTO laws(law_id, law_title, law_abbr,
                                    first_seen, last_saved, is_current, indexed)
                   VALUES(?,?,?,?,?,?,0)
                   ON CONFLICT(law_id) DO UPDATE SET
                        law_title = excluded.law_title,
                        law_abbr  = excluded.law_abbr,
                        last_saved= excluded.last_saved,
                        is_current= excluded.is_current""",
                [(k,t,a,now,now,int(f)) for k,f,t,a in rows]
            )
        else:
            await db.executemany(
                """INSERT INTO precedents(prec_id, first_seen, last_saved, indexed)
                   VALUES(?,?,?,0)
                   ON CONFLICT(prec_id) DO UPDATE SET
                        last_saved=excluded.last_saved""",
                [(k,now,now) for k, *_ in rows]
            )
        await db.commit()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ ë£¨í‹´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def pipeline(target:str):
    async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(limit=MAX_CONC)) as session:
        masters = await collect_master(session, target)
        kind = "ë²•ë ¹" if target=="law" else "íŒë¡€"
        print(f"â—Ž {kind} {len(masters):,}ê±´ ì²˜ë¦¬ ì‹œìž‘ (ë™ì‹œ {MAX_CONC})")

        batch, tasks = [], []
        sem = asyncio.Semaphore(MAX_CONC)

        async def sem_worker(m,f):
            async with sem:
                return await worker(m,f,target,session)

        for m,f in masters:
            tasks.append(asyncio.create_task(sem_worker(m,f)))

        for coro in tqdm(asyncio.as_completed(tasks), total=len(tasks),
                         desc=f"ì²˜ë¦¬ì¤‘({kind})", unit="item"):
            key, flag, title, abbr = await coro
            if key:
                batch.append((key, flag, title, abbr))
            if len(batch) >= 500:
                await upsert_many(batch, "laws" if target=="law" else "precedents")
                batch.clear()

        if batch:
            await upsert_many(batch, "laws" if target=="law" else "precedents")
        print(f"â˜… {kind} ì™„ë£Œ")

async def main():
    await init_db()
    await pipeline("law")
    await pipeline("prec")
    print("ðŸŽ‰ ëª¨ë“  ìž‘ì—… ì™„ë£Œ")

if __name__ == "__main__":
    asyncio.run(main())
